{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# **数据挖掘——Home Credit Default Risk**\n",
    "\n",
    "Authors：李林（3120220938）、杨洋（3220211141）、敬甲男（3220221052）、李翰杰（3120220936）\n",
    "\n",
    "github地址：https://github.com/leealim/kaggle-Home-Credit-Default-Risk\n",
    "\n",
    "---\n",
    "\n",
    "## 特征工程——特征增加\n",
    "\n",
    "通过各种方式，增加特征：\n",
    "> 简单计算的特征\n",
    "> 融合原有的数据表中的数据的特征\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引入本部分所需要的包，并定义需要的值和函数\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "\n",
    "source_dir=\"..\\\\data\\\\outlier_handling\"\n",
    "result_dir=\"..\\\\data\\\\table_merge\"\n",
    "\n",
    "app_tr_path = source_dir+\"\\\\application_train.csv\"\n",
    "app_te_path = source_dir+\"\\\\application_test.csv\"\n",
    "bur_path = source_dir+\"\\\\bureau.csv\"\n",
    "bur_bal_path = source_dir+\"\\\\bureau_balance.csv\"\n",
    "pos_path = source_dir+\"\\\\POS_CASH_balance.csv\"\n",
    "cre_path = source_dir+\"\\\\credit_card_balance.csv\"\n",
    "pre_path = source_dir+\"\\\\previous_application.csv\"\n",
    "ins_path = source_dir+\"\\\\installments_payments.csv\"\n",
    "hom_path = \"..\\\\data\\\\home-credit-default-risk\\\\HomeCredit_columns_description.csv\"  # 列描述表\n",
    "hom = pd.read_csv(hom_path)\n",
    "\n",
    "if not os.path.exists(result_dir):\n",
    "    os.makedirs(result_dir)\n",
    "\n",
    "def agg_numeric(df, parent_var, df_name):\n",
    "    \n",
    "    #排除其他键\n",
    "    for col in df:\n",
    "        if col != parent_var and 'SK_ID' in col:\n",
    "            df = df.drop(columns = col)\n",
    "    \n",
    "    #聚合\n",
    "    parent_ids = df[parent_var].copy()\n",
    "    numeric_df = df.select_dtypes('number').copy()\n",
    "    numeric_df[parent_var] = parent_ids\n",
    "    agg = numeric_df.groupby(parent_var).agg(['count', 'mean', 'max', 'min', 'sum'])\n",
    "\n",
    "    #重命名列\n",
    "    columns = []\n",
    "    for var in agg.columns.levels[0]:\n",
    "        if var != parent_var:\n",
    "            for stat in agg.columns.levels[1]:\n",
    "                columns.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    agg.columns = columns\n",
    "    \n",
    "    #排除重复列\n",
    "    _, idx = np.unique(agg, axis = 1, return_index=True)\n",
    "    agg = agg.iloc[:, idx]\n",
    "    \n",
    "    return agg\n",
    "\n",
    "def agg_categorical(df, parent_var, df_name):\n",
    "\n",
    "    categorical = pd.get_dummies(df.select_dtypes('object'))\n",
    "    categorical[parent_var] = df[parent_var]\n",
    "    categorical = categorical.groupby(parent_var).agg(['sum', 'count', 'mean'])\n",
    "    \n",
    "    #重命名\n",
    "    column_names = []\n",
    "    for var in categorical.columns.levels[0]:\n",
    "        for stat in ['sum', 'count', 'mean']:\n",
    "            column_names.append('%s_%s_%s' % (df_name, var, stat))\n",
    "    categorical.columns = column_names\n",
    "    \n",
    "    #排除重复\n",
    "    _, idx = np.unique(categorical, axis = 1, return_index = True)\n",
    "    categorical = categorical.iloc[:, idx]\n",
    "    \n",
    "    return categorical\n",
    "\n",
    "def aggregate_client(df, group_vars, df_names):\n",
    "    #聚合多键关系表信息\n",
    "    df_agg = agg_numeric(df, parent_var = group_vars[0], df_name = df_names[0])\n",
    "    if any(df.dtypes == 'category'):\n",
    "        df_counts = agg_categorical(df, parent_var = group_vars[0], df_name = df_names[0])\n",
    "        df_by_loan = df_counts.merge(df_agg, on = group_vars[0], how = 'outer')\n",
    "        df_by_loan = df_by_loan.merge(df[[group_vars[0], group_vars[1]]], on = group_vars[0], how = 'left')\n",
    "        df_by_loan = df_by_loan.drop(columns = [group_vars[0]])\n",
    "        df_by_client = agg_numeric(df_by_loan, parent_var = group_vars[1], df_name = df_names[1])\n",
    "    else:\n",
    "        df_by_loan = df_agg.merge(df[[group_vars[0], group_vars[1]]], on = group_vars[0], how = 'left')\n",
    "        df_by_loan = df_by_loan.drop(columns = [group_vars[0]])\n",
    "        df_by_client = agg_numeric(df_by_loan, parent_var = group_vars[1], df_name = df_names[1])\n",
    "        \n",
    "    return df_by_client\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_tr = pd.read_csv(app_tr_path)\n",
    "app_te = pd.read_csv(app_te_path)\n",
    "pre = pd.read_csv(pre_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 将主表的分类数据转换成数值数据\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290621, 80)\n",
      "(48744, 79)\n"
     ]
    }
   ],
   "source": [
    "print(app_tr.shape)\n",
    "print(app_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用聚合函数产生聚合信息后，直接聚合到主表\n",
    "\n",
    "pre_agg = agg_numeric(pre, 'SK_ID_CURR', 'previous')\n",
    "pre_count = agg_categorical(pre, 'SK_ID_CURR', 'previous')\n",
    "\n",
    "\n",
    "app_tr = app_tr.merge(pre_agg, on ='SK_ID_CURR', how = 'left')\n",
    "app_tr = app_tr.merge(pre_count, on = 'SK_ID_CURR', how = 'left')\n",
    "app_te = app_te.merge(pre_agg, on ='SK_ID_CURR', how = 'left')\n",
    "app_te = app_te.merge(pre_count, on = 'SK_ID_CURR', how = 'left')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cash = pd.read_csv('../data/home-credit-default-risk/POS_CASH_balance.csv')\n",
    "# cash_by_client = aggregate_client(cash, group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], df_names = ['cash', 'client'])\n",
    "# app_tr = app_tr.merge(cash_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "# app_te = app_te.merge(cash_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# credit = pd.read_csv('../data//home-credit-default-risk/credit_card_balance.csv')\n",
    "# credit_by_client = aggregate_client(credit, group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], df_names = ['credit', 'client'])\n",
    "# app_tr = app_tr.merge(credit_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "# app_te = app_te.merge(credit_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "\n",
    "# installments = pd.read_csv('../data//home-credit-default-risk/installments_payments.csv')\n",
    "# installments_by_client = aggregate_client(installments, group_vars = ['SK_ID_PREV', 'SK_ID_CURR'], df_names = ['installments', 'client'])\n",
    "# app_tr = app_tr.merge(installments_by_client, on = 'SK_ID_CURR', how = 'left')\n",
    "# app_te = app_te.merge(installments_by_client, on = 'SK_ID_CURR', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = preprocessing.LabelEncoder()\n",
    "le_count = 0\n",
    "for col in app_tr:\n",
    "    if app_tr[col].dtype == 'object':\n",
    "        if len(list(app_tr[col].unique())) <= 2:\n",
    "            le.fit(app_tr[col])\n",
    "            app_tr[col] = le.transform(app_tr[col])\n",
    "            app_te[col] = le.transform(app_te[col])\n",
    "            le_count += 1\n",
    "\n",
    "app_tr = pd.get_dummies(app_tr)\n",
    "app_te = pd.get_dummies(app_te)\n",
    "\n",
    "train_labels = app_tr['TARGET']\n",
    "app_tr, app_te = app_tr.align(app_te, join = 'inner', axis = 1)\n",
    "app_tr['TARGET'] = train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(290621, 572)\n",
      "(48744, 571)\n"
     ]
    }
   ],
   "source": [
    "print(app_tr.shape)\n",
    "print(app_te.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#结果保存\n",
    "\n",
    "app_tr.to_csv(result_dir+\"\\\\application_train.csv\",index=False)\n",
    "app_te.to_csv(result_dir+\"\\\\application_test.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcdrvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
